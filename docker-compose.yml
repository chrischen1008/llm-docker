version: "3.9"

services:
  vllm-service:
    image: vllm/vllm-openai:latest
    container_name: my_vllm_container
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models:ro
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - VLLM_LOGGING_LEVEL=INFO
      - HF_HUB_OFFLINE=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: ["gpu"]
    command:
      [
        "--model", "/models/deepseek-coder-1.3b-instruct",
        "--served-model-name", "deepseek-coder-1.3b-instruct",
        "--gpu-memory-utilization", "0.8",
        "--max-model-len", "8000",
        "--max-num-seqs", "10",
        "--quantization", "fp8", 
        "--port", "8000"
      ]


  streamlit-sqlcoder:
    build:
      context: .
      dockerfile_inline: |
        FROM python:3.10-slim

        # 設定為非互動模式，避免安裝過程中斷
        ENV DEBIAN_FRONTEND=noninteractive

        # 更新、安裝必要的套件，並在單一指令層中完成清理，以縮小映像檔體積
        RUN apt-get update && apt-get install -y --no-install-recommends \
          gcc g++ curl \
          && apt-get clean \
          && rm -rf /var/lib/apt/lists/*

        WORKDIR /app
        COPY requirements.txt . 
        RUN pip install --no-cache-dir -r requirements.txt
        COPY . .

        EXPOSE 8501
        CMD ["streamlit", "run", "rag_chatroom_vllm_sql.py", "--server.address", "0.0.0.0"]

    container_name: my_streamlit_sqlcoder
    ports:
      - "8501:8501"
    volumes:
      - ./.env:/app/.env:ro
    environment:
      - LLM_API_URL=http://vllm-service:8000
      - LLM_MODEL=deepseek-coder-1.3b-instruct
    depends_on:
      - vllm-service




