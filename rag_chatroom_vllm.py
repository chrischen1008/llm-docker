import streamlit as st
import json
import pandas as pd
from opencc import OpenCC
import re, os, time
from io import StringIO
from dotenv import load_dotenv

from openai import OpenAI  # âœ… vLLM ç”¨ OpenAI ç›¸å®¹ API

#! åŸ·è¡Œå‘½ä»¤ : streamlit run rag_chatroom.py
# ==== ç’°å¢ƒè¨­å®š ====
load_dotenv()
LLM_MODEL = os.getenv("LLM_MODEL")
VLLM_ENDPOINT = os.getenv("VLLM_ENDPOINT", "http://vllm-service:8000/v1")  # vLLM API URL

client = OpenAI(base_url=VLLM_ENDPOINT, api_key="EMPTY")  # vLLM é è¨­ä¸ç”¨ keyï¼Œå¯éš¨ä¾¿å¡«

# ==== å·¥å…·å‡½æ•¸ ====
def remove_think_tags(text):
    return re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()

cc = OpenCC("s2t")
def enforce_traditional(text):
    return cc.convert(text)

# ==== è®€å– ERP JSON è³‡æ–™ ====
JSON_FILE = "erp_data.json"
with open(JSON_FILE, "r", encoding="utf-8") as f:
    DATA_JSON = json.load(f)

# ==== Streamlit ç‹€æ…‹ ====
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹ ERP åŠ©ç†ï¼Œæœƒæ ¹æ“š ERP JSON è³‡æ–™å›ç­”å•é¡Œã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸è¦ç”¢ç”Ÿ SQLã€‚å›ç­”æ ¼å¼å„ªå…ˆè€ƒæ…® CSVã€‚è¡¨æ ¼å…§å®¹å…¨éƒ¨ä½¿ç”¨ä¸­æ–‡"},
        {"role": "system", "content": f"ä»¥ä¸‹æ˜¯ ERP JSON è³‡æ–™ï¼š\n{json.dumps(DATA_JSON, ensure_ascii=False, indent=2)}"}
    ]

# ==== å•ç­”å‡½æ•¸ ====
def ask_llm(question: str):
    st.session_state.messages.append({"role": "user", "content": question})

    resp = client.chat.completions.create(
        model=LLM_MODEL,
        messages=st.session_state.messages,
        stream=False  # å¦‚æœè¦é€å­—è¼¸å‡ºå¯è¨­ True
    )

    answer = enforce_traditional(remove_think_tags(resp.choices[0].message.content))
    st.session_state.messages.append({"role": "assistant", "content": answer})
    return answer

# ==== Streamlit ä»‹é¢ ====
st.set_page_config(page_title="ERP èŠå¤©å®¤", layout="centered")
st.title("ğŸ’¬ ERP èŠå¤©å®¤")

# é¡¯ç¤ºæ­·å²è¨Šæ¯
for msg in st.session_state.messages:
    if msg["role"] == "user":
        with st.chat_message("user"):
            st.markdown(msg["content"])
    elif msg["role"] == "assistant":
        with st.chat_message("assistant"):
            st.markdown(msg["content"])

# è¼¸å…¥æ¡†
if prompt := st.chat_input("è«‹è¼¸å…¥å•é¡Œï¼Œä¾‹å¦‚ï¼šB00022 çš„è‰²ç¢¼ï¼Ÿ"):
    with st.chat_message("user"):
        st.markdown(prompt)

    answer = ask_llm(prompt)

    # ==== é€å­—é¡¯ç¤ºæ•ˆæœ ====
    with st.chat_message("assistant"):
        placeholder = st.empty()
        typed_text = ""
        for ch in answer:
            typed_text += ch
            placeholder.markdown(typed_text)
            time.sleep(0.02)

    # ==== ç›´æ¥è§£æ LLM å›ç­”çš„ CSV æ–‡å­—æˆè¡¨æ ¼ ====
    if "," in answer:  # ç²—ç•¥åˆ¤æ–·åƒ CSV
        try:
            df = pd.read_csv(StringIO(answer))
            st.dataframe(df, use_container_width=True)
        except Exception as e:
            st.warning(f"âš ï¸ å›ç­”ä¸æ˜¯æ¨™æº– CSVï¼Œç„¡æ³•é¡¯ç¤ºæˆè¡¨æ ¼ï¼š{e}")
            
        with open("output.csv", "w", encoding="utf-8-sig") as f:
            f.write(answer)
